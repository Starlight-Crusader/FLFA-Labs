# Determinism in Finite Automata. Conversion from NDFA 2 DFA. Chomsky Hierarchy
### Course: Formal Languages & Finite Automata
### Author: **Kalamaghin Arteom (FAF-211)**

## Objectives

**1.** Understand what an automaton is and what it can be used for.

**2.** Continuing the work in the same repository and the same project, the following need to be added: 

        a. Provide a function in your grammar type/class that could classify the grammar based on Chomsky hierarchy;
        b. For this you can use the variant from the previous lab.

**3.** According to your variant number (by universal convention it is register ID), get the finite automaton definition and do the following tasks:

        a. Implement conversion of a finite automaton to a regular grammar;
        b. Determine whether your FA is deterministic or non-deterministic;
        c. Implement some functionality that would convert an NDFA to a DFA;
        d. (Optional - bonus point) Represent the finite automaton graphically (Optional, and can be considered as a bonus point).


## ! Before diving in the report !

Ok, I admit this shit ended up pretty fucking messy, because I was not carefull while reading the assignment (I've even implemented conversion of an automata to a regular expression, since my brain ahve interpreted _to a regular grammar_ as _to a regular expression_). Anyways I will try to provide you with explicit explanation.

## Theoretical Notes
### **Chomsky Hierarchy in Theory of Computation**

According to Chomsky hierarchy, grammar is divided into **4 types** as follows: 

    Type 0 is known as unrestricted grammar,
    Type 1 is known as context-sensitive grammar,
    Type 2 is known as a context-free grammar,
    Type 3 Regular Grammar.

### Type 0

Type-0 grammars include all formal grammar. Type 0 grammar languages are recognized by turing machine. These languages are also known as the **Recursively Enumerable languages**.

Grammar Production in the form A -> B where:

    A is (N + T)* N (N + T)* ; B is (N + T)*

In type 0 there must be at least one N on the left side of production.

### Type 1

Type-1 grammars generate **context-sensitive languages**. The language generated by the grammar is recognized by the Linear Bound Automata. In Type 1:

    * First of all Type 1 grammar should be Type 0; 
    * Grammar Production in the form of: A -> B, where |A| <= |B|

### Type 2 

Type-2 grammars generate **context-free languages**. The language generated by the grammar is recognized by a Pushdown automata. In Type 2:

    * First of all, it should be Type 1; 
    * The left-hand side of production can have only one N (|A| = 1) and there is no restriction on B

### Type 3

Type-3 grammars generate **regular languages**. These languages are exactly all languages that can be accepted by a finite-state automaton. Type 3 is the most restricted form of grammar. Type 3 should be in the given form only:

    N -> NT* | T* (extended left-regular grammar)
                        (or)
    N -> T*N | T* (extended right-regular grammar)

These rules will be used to determine the type of grammar in the first exercise.

### **State elimination mathod**

_This was not required, but I accidentally did it so I mention this._

Every finite automaton has an equivalent regular expression. The conversion of a finite automaton to a regular expression is done through the **state elimination method**.

State elimination method

The State elimination method follows the following general set of rules:

    I. Add a new initial state (qi); make a null transition from the old initial state to the new initial state;
    II. Add a new final state (qf). Make null transition(s) to the new final state;
    III. Eliminate all states, except qi and qf, in the given finite automaton. Perform the elimination of states by checking the in-degrees and out-degrees of states and taking a cross product.

After steps 1 and 2, the qi state will not have any inward transitions, and the state qf state will not have any outward transitions. Step III involves:

    1. Choosing of an arbitrary state - k (beside qi and qf);
    2. Checking all the in-degrees (p) and out-degrees (q) of states and taking a cross product (p, q);
    3. Calculationg new transitions for (p, q) according to the formula t(p, q) = t(p, k) t(k, k)* t(k, q);
    4. Eliminating all the transitions mentioning k and adding calculated in the previous step.

    * Repeat while |Q| > 2

This method lies at the base of the algorithm implemented by me.

###  **NFA to DFA conversion**

Steps for converting NFA to DFA:

    Step 1: Initially Q' = Ï•;
    Step 2: Add q0 of NFA to Q'. Then find the transitions from this start state;
    Step 3: In Q', find the possible set of states for each input symbol; if this set of states is not in Q', then add it to Q';
    Step 4: In DFA, the final state will be all the states which contain F(final states of NFA).


## Impelementation description

**2.a. - Classification** 

The rules listed above have been written as functions that return true if the rule is respected.

```cpp
bool Classifier::type1Test(string left, string right) {
    if(left.length() <= right.length()) {
        return true;
    } else {
        return false;
    }
};

bool Classifier::type2Test(string left) {
    if(left.length() == 1) {
        return true;
    } else {
        return false;
    }
};

bool Classifier::type3Test(string right, int* al) {
    int numOfCaps = 0;

    for(int i = 0; i < right.length(); i++) {
        if(right[i] >= 'A' && right[i] <= 'Z') { numOfCaps++; } 
    }

    if(numOfCaps == 0) {
        return true;
    } else if(numOfCaps > 1) {
        return false;
    }

    if(right[0] >= 'A' && right[0] <= 'Z') {
        if(*al == 1) {
            return false;
        } else {
            *al = -1;
            return true;
        }
    } else if(right[right.length()-1] >= 'A' && right[right.length()-1] <= 'Z') {
        if(*al == -1) {
            return false;
        } else {
            *al = 1;
            return true;
        }
    } else {
        return false;
    }
};
```

To comply with the last condition (Type 3) it is also important to remember whether the previous ones were left or right. 

Next, each of the rules goes through three checks and gets a type from 0 to 3 assigned. The minimum of these values will be the type of the entire grammar.

```cpp
...
for(rule_it = ruleset.begin(); rule_it != ruleset.end(); ++rule_it) {
    rule = *rule_it;
    
    for(int i = 0; i < rule.length(); i++) {
        if(rule[i] == '>') {
            left_part = rule.substr(0, i-2);
            right_part = rule.substr(i+2, rule.length()-i-2);

            break;
        }
    }

    if(Classifier::type1Test(left_part, right_part)) {
        *(res+distance(ruleset.begin(), rule_it)) = 1;
    } else {
        continue;
    }

    if(Classifier::type2Test(left_part)) {
        *(res+distance(ruleset.begin(), rule_it)) = 2;
    } else {
        continue;
    }

    if(Classifier::type3Test(right_part, &alignment)) {
        *(res+distance(ruleset.begin(), rule_it)) = 3;
    }
}

for(int i = 0; i < ruleset.size(); i++) {
    if(*(res+i) < type) {
        type = *(res+i);
    }
}
...
```

The grammar offered to me, written to the file (rules.txt), belongs to the third type. By modifying the file, other types of grammars were also checked.

**3.a.1. Automaton to Regular Expression**

The code proposed below, executed in the cpp language, is a literal implementation of the algorithm described in the _Theoretical Notes_ section.

```cpp
...
while(Q.size() > 2) {
    state_to_eliminate = Q.front();
    in.clear(); out.clear(); newTransitions.clear();

    for(tr = T.begin(); tr != T.end(); tr++) {
        if(tr->target == state_to_eliminate && tr->source != state_to_eliminate) {
            if(find(in.begin(), in.end(), tr->source) == in.end()) {
                in.push_back(tr->source);
            }
        }

        if(tr->source == state_to_eliminate && tr->target != state_to_eliminate) {
            if(find(out.begin(), out.end(), tr->target) == out.end()) {
                out.push_back(tr->target);
            }
        }
    }

    ...

    for(p = in.begin(); p != in.end(); p++) {
        for(q = out.begin(); q != out.end(); q++) {
            if(*p == *q) { continue; }
            alpha = "";
                
            part = "";
            for(tr = T.begin(); tr != T.end(); tr++) {
                if(tr->source == *p && tr->target == state_to_eliminate) {
                    if(part.length() == 0) {
                        part += tr->character;
                    } else {
                        if(part[0] != '(') { part = '(' + part; }
                        part += '+'; part += tr->character;
                    }
                }
            }
            if(part[0] == '(') { part += ')'; }

            if(part.length() > 0) { alpha += part; }

            part = "";
            for(tr = T.begin(); tr != T.end(); tr++) {
                if(tr->source == state_to_eliminate && tr->target == state_to_eliminate) {
                    if(part.length() == 0) {
                        part += tr->character; part += '*';
                    } else {
                        if(part[0] != '(') { part = '(' + part; }
                        part += '+'; part += tr->character; part += '*';
                    }
                }
            }
            if(part[0] == '(') { part += ')'; }

            if(part.length() > 0) { alpha += part; }

            part = "";
            for(tr = T.begin(); tr != T.end(); tr++) {
                if(tr->source == state_to_eliminate && tr->target == *q) {
                    if(part.length() == 0) {
                        part += tr->character;
                    } else {
                        if(part[0] != '(') { part = '(' + part; }
                        part += '+'; part += tr->character;
                    }
                }
            }
            if(part[0] == '(') { part += ')'; }

            if(part.length() > 0) { alpha += part; }

            res.source = *p; res.character = alpha; res.target = *q;

            newTransitions.push_back(res);
        }
    }

    eliminated = true;

    while(eliminated) {
        eliminated = false;

        for(tr = T.begin(); tr != T.end(); tr++) {
                
            if((tr->source == state_to_eliminate || tr->target == state_to_eliminate) || (tr->source == Q.back() && tr->target == F.front())) {
                res.source = T.front().source;
                res.character = T.front().character;
                res.target = T.front().target;

                T.front().source = tr->source;
                T.front().character = tr->character;
                T.front().target = tr->target;

                tr->source = res.source;
                tr->character = res.character;
                tr->target = res.target;

                T.pop_front();

                eliminated = true;
                break;
            }
        }
    }

    ...

    while(newTransitions.size() > 0) {
        T.push_back(newTransitions.front());
        newTransitions.pop_front();
    }

    Q.pop_front();

    ...
}

string answer = T.back().character;
string epsilon = "eps";

for(int i = 0; i < answer.length()-2; i++) {
    if(answer.substr(i, 3) == epsilon) {
        answer = answer.substr(0, i) + '[' + answer.substr(i, 3) + ']' + answer.substr(i+3, answer.length()-i-3);
        i++;
    }
}
...
```

For my variant I've got: 

    THE NFA TO RE ANS : [eps]a*ac*bbac*b[eps]

**3.a.2 Automata to Regular Grammar**

Nothing complicated. We rewrite the rules of the automaton, and if the left part has already been met in one of the rewritten rules, we add the right part to the already existing one through '|'.

```cpp
for(itt = T.begin(); itt != T.end(); itt++) {
    updated = false;

    for(itr = ruleset.begin(); itr != ruleset.end(); itr++) {
        if(itt->source == itr->source) {
            itr->target += '|'; itr->target += itt->character; itr->target += itt->target;
            updated = true;
        }
    }

    if(updated) { 
        continue; 
    } else {
        newRule.source = itt->source;
        newRule.target = itt->character;
        newRule.target += itt->target;

        ruleset.push_back(newRule);
    }
}
```

Output:

    THE NFA TO RG ANS : 
    q0 -> aq0|aq1
    q1 -> cq1|bq2
    q2 -> bq3
    q3 -> aq1

**3.b. Distinguish NFA and DFA**

```cpp
...
list<Transition>::iterator tr;
list<string>::iterator qi, ei;
string qs, es;
int i1, i2;
    
for(tr = T.begin(); tr != T.end(); tr++) {
    qs = tr->source; es = tr->character;
    qi = find(Q.begin(), Q.end(), qs); ei = find(E.begin(), E.end(), es);
    i1 = distance(Q.begin(), qi); i2 = distance(E.begin(), ei);

    count[i1][i2]++;

    if(count[i1][i2] > 1) {
        line = "NFA";
        return line;
    }
}

line = "DFA";
return line;
...
```

The idea behind this one is also quite simple. We read Q, E, F and delta-s from the file. Then we declare a 2D array of size |Q| * |E| - count. We go through the delta-s and increment count[Q.idx(del.left_part)][E.idx(del.character)]. We immediately check if count[Q.idx(del.left_part)][E.idx(del.character)] is greater than 1, we issue a verdict immediately - NFA. If it hasn't come to this - DFA.

**3.c. NFA to DFA conversion**

Again, the algorithm is described in the _Theoretical Notes_ section.

```cpp
...
qd = dfa.Q.begin();
while(qd != dfa.Q.end()) {
    for(ed = dfa.E.begin(); ed != dfa.E.end(); ++ed) {
        j1 = distance(dfa.Q.begin(), qd); j2 = distance(dfa.E.begin(), ed);
        *(temp_graph+j1*dfa.E.size()+j2) = "";

        qs = *qd; qs += '<';
        states_to_check.clear();

        for(int i = 0; i < qs.length(); i++) {
            if(i == 0 || qs[i] == '|') {
                if(i == 0) { start = 0; } 
                else { start = 1; }

                temp = Miscellaneous::readNextToken(qs.substr(i+start, qs.length()-i));
                if(temp.length() > 0) { states_to_check.push_back(temp); }
            }
        }

        es = *ed; en = find(nfa.E.begin(), nfa.E.end(), es); i2 = distance(nfa.E.begin(), en);

        for(state = states_to_check.begin(); state != states_to_check.end(); ++state) {
            qs = *state; qn = find(nfa.Q.begin(), nfa.Q.end(), qs); i1 = distance(nfa.Q.begin(), qn);
            if((temp_graph+j1*dfa.E.size()+j2)->length() > 0) { *(temp_graph+j1*dfa.E.size()+j2) += '|'; }
            if((nfa.graph+i1*nfa.E.size()+i2)->length() > 1) {
                *(temp_graph+j1*dfa.E.size()+j2) += *(nfa.graph+i1*nfa.E.size()+i2);
            }
        }

        temp = *(temp_graph+j1*dfa.E.size()+j2);
        if(temp[temp.length()-1] == '|') {
            *(temp_graph+j1*dfa.E.size()+j2) = temp.substr(0, temp.length()-1);
        }
        *(temp_graph+j1*dfa.E.size()+j2) = Miscellaneous::normalizeComposite(*(temp_graph+j1*dfa.E.size()+j2));

        temp = *(temp_graph+j1*dfa.E.size()+j2);

        if((find(dfa.Q.begin(), dfa.Q.end(), temp) == dfa.Q.end()) && (temp.length() > 0)) {
            dfa.Q.push_back(temp);
        }
    }

    qd++;
}

dfa.graph = new string[dfa.Q.size()*dfa.E.size()];

for(int i = 0; i < dfa.Q.size(); i++) {
    for(int j = 0; j < dfa.E.size(); j++) {
        *(dfa.graph+i*dfa.E.size()+j) = *(temp_graph+i*dfa.E.size()+j);
    }
}
    
size_t found;

for(qd = dfa.Q.begin(); qd != dfa.Q.end(); ++qd) {
    st = *qd;

    for(qn = nfa.F.begin(); qn != nfa.F.end(); ++qn) {
        temp = *qn;
        found = st.find(temp);

        if(found != string::npos) {
            if(find(dfa.F.begin(), dfa.F.end(), st) == dfa.F.end()) {
                dfa.F.push_back(st);
            }
        }
    }
}
...
```

Result:

    NFA:
    Q = { q0, q1, q2, q3, EOL }
    E = { a, c, b, EOL }
    F = { q2, EOL }
    d(q0,a) = q0|q1
    d(q1,c) = q1
    d(q1,b) = q2
    d(q2,b) = q3
    d(q3,a) = q1

    DFA:
    Q = { q0, q0|q1, q1, q2, q3, EOL }
    E = { a, c, b, EOL }
    F = { q2, EOL }
    d(q0,a) = q0|q1
    d(q0|q1,a) = q0|q1
    d(q0|q1,c) = q1
    d(q0|q1,b) = q2
    d(q1,c) = q1
    d(q1,b) = q2
    d(q2,b) = q3
    d(q3,a) = q1

## Conclusions

Regular grammar and final state machines are indeed powerful tools for information conveying and lexical analysis. During this lab, I was able to both gain a stronger grasp on these concepts in particular, and formal languages in general, and develop my technical skills.

## References

1. _Programming Language Syntax_ - Michael L. Scott, in Programming Language Pragmatics (Third Edition), 2009;
2. https://en.wikipedia.org/wiki/Finite-state_machine;
3. _Formal Languages and Finite Automata_ [Guide for practical lessons] - UTM;
4. https://www.educative.io/answers/how-to-convert-finite-automata-to-regular-expressions;
5. https://www.geeksforgeeks.org/chomsky-hierarchy-in-theory-of-computation/.

